Singularity> python main.py --mode prune --prune_layers 0
Using device: cuda
Loading model: meta-llama/Llama-3.2-3B-Instruct
Loading checkpoint shards: 100%|███████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.05it/s]

=== Running Pruning Simulation ===
Model configuration: 28 layers, 24 attention heads, 8 KV heads, 128 dims per head
Original KV cache - Key sparsity: 0.00%, Value sparsity: 0.00%
Pruned KV cache - Key sparsity: 3.57%, Value sparsity: 3.57%

=== Pruning Simulation Results ===
Baseline Perplexity: 17.5942
Pruned Perplexity: 17.5942
Perplexity Change: 0.00%
Baseline Latency: 14.24 ms
Pruned Latency: 14.19 ms
Latency Change: -0.40%
Pruned layers: [0]

Done!
Total execution time: 5.35 seconds